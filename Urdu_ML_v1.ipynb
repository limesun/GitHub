{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Urdu_ML_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limesun/GitHub/blob/master/Urdu_ML_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6S35-g6eFU",
        "colab_type": "text"
      },
      "source": [
        "# Import Data & Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07DU3WFWA9Wp",
        "colab_type": "text"
      },
      "source": [
        "Hello, the new type of text data - Urdu language for sentiment analysis! \n",
        "\n",
        "Let's start to import the dataset from my Github and to install/import some required python libraries.\n",
        "\n",
        "(Oh, as there was no column name in the dataset, I gave them before I imported the dataset for later conveniences in the data analysis.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KTynRzq_K9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d0261c3-f41d-4b9c-a651-320c4d46b03a"
      },
      "source": [
        "pip install cytoolz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cytoolz in /usr/local/lib/python3.6/dist-packages (0.9.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPtDTxprnUWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import required libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "import math\n",
        "import re\n",
        "import string\n",
        "from cytoolz import concat\n",
        "\n",
        "#Import the dataset\n",
        "url = 'https://raw.githubusercontent.com/limesun/Sentiment_Analysis_Urdu_Language/master/Roman%20Urdu%20DataSet_my.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ49kISP-uAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "eae92533-7ee7-4500-ee78-b81464836506"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sahi bt h</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kya bt hai,</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wah je wah</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Are wha kaya bat hai</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review Sentiment\n",
              "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive\n",
              "1                                          sahi bt h  Positive\n",
              "2                                        Kya bt hai,  Positive\n",
              "3                                         Wah je wah  Positive\n",
              "4                               Are wha kaya bat hai  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2nKotR0pdBY",
        "colab_type": "text"
      },
      "source": [
        "#Data Cleaning & Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb-z6KA_BhWd",
        "colab_type": "text"
      },
      "source": [
        "After I looked into the dataset, I found that the language is not familiar to me at all. However, fortunetly, I still could get some ideas about this dataset through the study.\n",
        "\n",
        "It was a social media review dataset, so it is including relatively short and messy texts as well as emoji like tweets. \n",
        "\n",
        "Thus, I decided to use 'TweetTokenizer' later for the tokenization to handle emoji and some weired expression like 'goooooooood'.\n",
        "\n",
        "Before I applied the text pre-processing task, I had to do some data cleaning task first as I found one row incluing wrong spelling of 'Neative' instead of 'Negative' in Sentiment column as well as one null data row and many empty rows in Review column. \n",
        "\n",
        "The below codes are for the data cleaning tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oMGsTVpKIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_white_space_row(data):\n",
        "    #Remove white space\n",
        "    data['Review'] = data['Review'].apply(lambda x: ' '.join(x.split())) #remove the different types of whitespace\n",
        "    data['Review'].replace('', np.nan, inplace=True) #change the empty cell('') into nan value\n",
        "    #Drop null rows\n",
        "    data.dropna(subset=['Review'], inplace=True) #drop them all nan-value rows\n",
        "    return data\n",
        "\n",
        "def pre_processing(data):\n",
        "    #Lower case\n",
        "    data = data.astype(str).str.lower() \n",
        "    #Filter punctuation\n",
        "    data = data.astype(str).str.replace('[{}]'.format(string.punctuation), ' ') \n",
        "    #Filter number\n",
        "    data = data.apply(lambda x: ' '.join([item for item in str(x).split() if not item.isdigit()]))\n",
        "    data = data.astype(str).str.strip() #Filter Whitespace\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnskrCjPGCrW",
        "colab_type": "text"
      },
      "source": [
        "Then, I applied some text pre-processing procedures such as lower case normalization, filtering punctuations and numbers, but I was not able to apply some procedurea such as filtering stopwords or pos tagging as it is an unknown language for those things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4jU9TyQpnk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8511cfbf-7ff3-4d71-9e19-fa67ffa7660a"
      },
      "source": [
        "# 1. Wrong spelling in 'Sentiment'\n",
        "df.groupby('Sentiment').count()\n",
        "#df[df['Sentiment'] == 'Neative'] #Check the index of the probramatic rows\n",
        "df.loc[df['Sentiment'] == 'Neative', ['Sentiment']] = 'Negative'  # changed one row\n",
        "#df.loc[13277,:] #Verification\n",
        "df.groupby('Sentiment').count() #verification\n",
        "\n",
        "# 2. Null/NaN/empty in 'Review' \n",
        "np.where(pd.isnull(df)) #Null case - one row\n",
        "df.dropna(subset=['Review'], inplace=True)\n",
        "print(len(df))\n",
        "\n",
        "df = remove_white_space_row(df)\n",
        "print(len(df))\n",
        "df.Review = pre_processing(df.Review)\n",
        "print(len(df))\n",
        "df = remove_white_space_row(df)\n",
        "print(len(df))\n",
        "\n",
        "# 3. Drop 'Neutral' data so make it binary problem\n",
        "df = df[df.Sentiment != 'Neutral']\n",
        "df = df.reset_index(drop=True)\n",
        "len(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20228\n",
            "20116\n",
            "20116\n",
            "20045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11299"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBqOmVG4El4d",
        "colab_type": "text"
      },
      "source": [
        "I have also deleted 'Neutral' data as the target has a clear direction from positive to negative and it will make the prediction more efficient and accurate.\n",
        "\n",
        "After I have done the data cleaning tasks, I got a corpus having  '11,299' data records and its vocabrary size is '24,689'.\n",
        "\n",
        "The target (Sentiment) distribution is having a pretty good balance (pos 6013 :  neg 5286) so we may not need to worry about the unbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKXffyAd-SvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e200b468-3ff7-4088-fc9a-cd8b097730df"
      },
      "source": [
        "# Vocabrary Size Check\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "bow = df['Review'].apply(tokenizer.tokenize)\n",
        "f = pd.DataFrame({'all': pd.value_counts(list(concat(bow)))})\n",
        "corpus_size, vocab_size = len(df['Review']), len(f)\n",
        "print(corpus_size, vocab_size)\n",
        "#f.sort_values('all', ascending=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11299 24689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B5oMrLdpkbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "07b4c6f8-68cf-4a57-d9a5-404ff205cb9c"
      },
      "source": [
        "# Change 'Sentiment' in numerical categorical data\n",
        "df['Target_category'] = df['Sentiment'].factorize()[0]\n",
        "category_id_df = df[['Sentiment', 'Target_category']].drop_duplicates().sort_values('Target_category')\n",
        "category_to_id = dict(category_id_df.values)\n",
        "id_to_category = dict(category_id_df[['Target_category', 'Sentiment']].values)\n",
        "\n",
        "df.groupby(['Target_category', 'Sentiment'])['Review'].agg(['count'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target_category</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>Positive</th>\n",
              "      <td>6013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th>Negative</th>\n",
              "      <td>5286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           count\n",
              "Target_category Sentiment       \n",
              "0               Positive    6013\n",
              "1               Negative    5286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH3FQxzKp4K5",
        "colab_type": "text"
      },
      "source": [
        "#Word Representation & Conventional Machine Learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug2PxqM3Ftdf",
        "colab_type": "text"
      },
      "source": [
        "Now, let's start the main prediction task using conventional machine learning algorithms.\n",
        "\n",
        "For this part I chose 'TweetTokenizer' from NLTK for the tokenization and 'TF/TFIDF' from sklearn for the word represenation.\n",
        "\n",
        "I also chose five different alogorithms that are known as good predition methods for a text data.\n",
        "\n",
        "- Support Vector Machine(Linear)\n",
        "- Naive Baysian \n",
        "- Logistic Regression\n",
        "- Random Forest\n",
        "- Neural Network (Multi-Layer Perceptron)\n",
        "\n",
        "In the below code results, you can check each model performance with different word representatin methods and performance matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeALPL7Ipylp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras & sklearn libraries for various text mining techniques\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "'''\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SimpleRNN\n",
        "from keras.utils.np_utils import to_categorical\n",
        "'''\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAyJYKIXItuo",
        "colab_type": "text"
      },
      "source": [
        "I have splited the dataset into train and test dataset. The ratio is about 75%:25%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gafNqO5ZwCiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f8c81a6a-f517-4d4a-e1c5-23e1140e3e93"
      },
      "source": [
        "# Train & Test Split\n",
        "\n",
        "X = df.Review\n",
        "y = df.Target_category\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "\n",
        "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_train),\n",
        "                                                                                         (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n",
        "                                                                        (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))\n",
        "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_test),\n",
        "                                                                             (len(X_test[y_test == 0]) / (len(X_test)*1.))*100,\n",
        "                                                                            (len(X_test[y_test == 1]) / (len(X_test)*1.))*100))\n",
        "print(\"# of positive in train set :\", len(X_train[y_train == 0]))\n",
        "print(\"# of positive in test set :\", len(X_test[y_test == 0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has total 8474 entries with 53.46% negative, 46.54% positive\n",
            "Test set has total 2825 entries with 52.50% negative, 47.50% positive\n",
            "# of positive in train set : 4530\n",
            "# of positive in test set : 1483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAEQYpNgp8m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making two different word represenations using TweetTokenizer\n",
        "\n",
        "\n",
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "max_feature = 10000\n",
        "\n",
        "# TF_matrix\n",
        "cv = TfidfVectorizer(max_features=max_feature, ngram_range=(1,3), norm='l2', min_df = 0, use_idf=False, smooth_idf=False, lowercase = True, \n",
        "                                sublinear_tf=False, tokenizer=tokenizer.tokenize)\n",
        "\n",
        "\n",
        "# TFIDF_matrix\n",
        "tfidf = TfidfVectorizer(max_features=max_feature, ngram_range=(1,3), norm='l2', min_df = 0, use_idf=True, smooth_idf=False, lowercase = True, \n",
        "                                sublinear_tf=True, tokenizer=tokenizer.tokenize)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqaPrnESJMsH",
        "colab_type": "text"
      },
      "source": [
        "I gave the value of 10,000 on max_feature in generating the word representation based on the vocab_size (24,689) of the corpus as we shoud consider the Zip's law."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gFAvs6XrFT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Various Machine Learning Methods\n",
        "\n",
        "# set parameters\n",
        "models = [  LinearSVC(),\n",
        "            MultinomialNB(),\n",
        "            LogisticRegression(random_state=0),\n",
        "            RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0),\n",
        "            MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)]\n",
        "\n",
        "data_set =[cv, tfidf]\n",
        "data_set_name= [\"TF\", \"TFIDF\"]\n",
        "label_set = [df.Target_category, df.Target_category]            \n",
        "cross_validation = 5\n",
        "cv_df = pd.DataFrame(index=range(cross_validation * len(models)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymuz9nvQudhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2236
        },
        "outputId": "3eb31fe8-5766-49f5-dba8-a865842fe265"
      },
      "source": [
        "for data_set_index in range(len(data_set)):\n",
        "  \n",
        "  for model in models:\n",
        "   \n",
        "    model_name = model.__class__.__name__\n",
        "    pipeline = Pipeline([\n",
        "        ('vectorizer', data_set[data_set_index]),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(X_test)\n",
        "    \n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    print(\"Data set\", data_set_name[data_set_index])\n",
        "    print(\"Model name\", model_name)\n",
        "    print(classification_report(y_test, y_pred, target_names=['positive','negative']))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "Data set TF\n",
            "Model name LinearSVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.79      0.79      0.79      1483\n",
            "    negative       0.77      0.77      0.77      1342\n",
            "\n",
            "    accuracy                           0.78      2825\n",
            "   macro avg       0.78      0.78      0.78      2825\n",
            "weighted avg       0.78      0.78      0.78      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TF\n",
            "Model name MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.79      0.80      0.79      1483\n",
            "    negative       0.77      0.77      0.77      1342\n",
            "\n",
            "    accuracy                           0.78      2825\n",
            "   macro avg       0.78      0.78      0.78      2825\n",
            "weighted avg       0.78      0.78      0.78      2825\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "Data set TF\n",
            "Model name LogisticRegression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.77      0.79      0.78      1483\n",
            "    negative       0.76      0.74      0.75      1342\n",
            "\n",
            "    accuracy                           0.77      2825\n",
            "   macro avg       0.77      0.76      0.76      2825\n",
            "weighted avg       0.77      0.77      0.77      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TF\n",
            "Model name RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.54      0.99      0.70      1483\n",
            "    negative       0.91      0.08      0.15      1342\n",
            "\n",
            "    accuracy                           0.56      2825\n",
            "   macro avg       0.73      0.54      0.43      2825\n",
            "weighted avg       0.72      0.56      0.44      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TF\n",
            "Model name MLPClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.52      1.00      0.69      1483\n",
            "    negative       0.00      0.00      0.00      1342\n",
            "\n",
            "    accuracy                           0.52      2825\n",
            "   macro avg       0.26      0.50      0.34      2825\n",
            "weighted avg       0.28      0.52      0.36      2825\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "Data set TFIDF\n",
            "Model name LinearSVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.78      0.79      0.79      1483\n",
            "    negative       0.77      0.76      0.76      1342\n",
            "\n",
            "    accuracy                           0.77      2825\n",
            "   macro avg       0.77      0.77      0.77      2825\n",
            "weighted avg       0.77      0.77      0.77      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TFIDF\n",
            "Model name MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.81      0.79      0.80      1483\n",
            "    negative       0.77      0.79      0.78      1342\n",
            "\n",
            "    accuracy                           0.79      2825\n",
            "   macro avg       0.79      0.79      0.79      2825\n",
            "weighted avg       0.79      0.79      0.79      2825\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "Data set TFIDF\n",
            "Model name LogisticRegression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.78      0.80      0.79      1483\n",
            "    negative       0.77      0.75      0.76      1342\n",
            "\n",
            "    accuracy                           0.78      2825\n",
            "   macro avg       0.78      0.78      0.78      2825\n",
            "weighted avg       0.78      0.78      0.78      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TFIDF\n",
            "Model name RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.54      0.99      0.70      1483\n",
            "    negative       0.91      0.08      0.15      1342\n",
            "\n",
            "    accuracy                           0.56      2825\n",
            "   macro avg       0.73      0.54      0.43      2825\n",
            "weighted avg       0.72      0.56      0.44      2825\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Data set TFIDF\n",
            "Model name MLPClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.52      1.00      0.69      1483\n",
            "    negative       0.00      0.00      0.00      1342\n",
            "\n",
            "    accuracy                           0.52      2825\n",
            "   macro avg       0.26      0.50      0.34      2825\n",
            "weighted avg       0.28      0.52      0.36      2825\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djF-GOxfIEUe",
        "colab_type": "text"
      },
      "source": [
        "The results shows the prediction through Naive Baysian model with TFIDF is the best even though the prediction performances between SVM, NB, LR with TF and TFIDF are not that significantly diffrent each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7ibtRLIrax_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cb274fb-a632-42e3-ea6f-8aeeb9168033"
      },
      "source": [
        "import sklearn; print(sklearn.__version__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.21.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}